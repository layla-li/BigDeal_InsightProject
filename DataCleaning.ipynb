{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions preparation\n",
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def clean(data_raw):\n",
    "    \"\"\"\n",
    "    clean the input data for future use\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data: pd.DataFrame()\n",
    "    \n",
    "    Returns:\n",
    "    result pd.DataFrame() after cleaning\n",
    "    \n",
    "    Date: 1/21/2020\n",
    "    \"\"\"\n",
    "    \n",
    "    # copy data\n",
    "    data = data_raw.copy()\n",
    "    \n",
    "    # convert na to 0 for following columns\n",
    "    data[\"Comments_count\"].fillna(0, inplace=True)\n",
    "    data[\"Bookmarks_count\"].fillna(0, inplace=True)\n",
    "    data[\"Shares_count\"].fillna(0, inplace=True)\n",
    "    \n",
    "    # if End_date is NaN, use Posted_date values\n",
    "    data[\"End_date\"].fillna(data['Posted_date'], inplace=True)\n",
    "\n",
    "    # convert End_date and Posted_date string to datatime format\n",
    "    for key in [\"Posted\", \"End\"]:\n",
    "        data[key+'_date']= pd.to_datetime(data[key+'_date'])\n",
    "        \n",
    "    # if End_date is earlier than Posted_date, convert it to Posted_date\n",
    "    end_before_post = data[\"End_date\"] < data[\"Posted_date\"]\n",
    "    data.loc[end_before_post, \"End_date\"] = data.loc[end_before_post, \"Posted_date\"]\n",
    "    \n",
    "    for key in [\"Posted\", \"End\"]:\n",
    "        data[key+'_year'] = pd.DatetimeIndex(data[key+'_date']).year\n",
    "        data[key+'_month'] = pd.DatetimeIndex(data[key+'_date']).month\n",
    "        data[key+'_day'] = pd.DatetimeIndex(data[key+'_date']).day\n",
    "        data[key+'_weekday'] = data[key+'_date'].dt.weekday\n",
    "            \n",
    "    # extracting xx% off from Description\n",
    "    data['discount_per_cent'] = data[\"Description\"].str.extract(r'(?P<discount>\\d+)[%]')\n",
    "    data['discount_per_cent'] = data['discount_per_cent'].astype('float32')\n",
    "    #print(data['discount_per_cent'].head())\n",
    "    data.drop([\"Title\", \"Description\"], axis=1, inplace=True)\n",
    "    \n",
    "    # if discount value is not found, the discount_per_cent is nan. Drop such data.\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the holidays in US\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import holidays\n",
    "def get_holidays(yearrange = None):\n",
    "    \"\"\"\n",
    "    Get the pd.DataFrame containing all the holidays date and names for the given years\n",
    "    Parameters:\n",
    "    -----------\n",
    "    yearrange: list of years to be included in the result\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame of holidays' date and names\n",
    "    \"\"\"\n",
    "    if yearrange is None:\n",
    "        return None\n",
    "    \n",
    "    holidaydict = {\"date\": [], \"name\": []}\n",
    "    for date, name in holidays.US(years=yearrange).items():\n",
    "        if \"Observed\" in name:\n",
    "            continue\n",
    "        holidaydict[\"date\"].append(date)\n",
    "        holidaydict[\"name\"].append(name.replace(',', '').replace('\\'','').replace('.','').replace(' ', '_'))\n",
    "        #print(date, name)\n",
    "    pd_holiday = pd.DataFrame(holidaydict)\n",
    "    pd_holiday[\"date\"] = pd.to_datetime(pd_holiday[\"date\"])\n",
    "    return pd_holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def ndays_from_holiday(dfhday, hname, test_date):\n",
    "    \"\"\"\n",
    "    In the given holidays (dfhday), find the number of days away from the given holiday (hname).\n",
    "    Parameters:\n",
    "    -----------\n",
    "    dfhday: pd.DataFrame() with two columns \"date\", \"name\" of the holidays\n",
    "    hname: string, given holiday name\n",
    "    test_date: datetime, date to be calculated for the ndays to holidays\n",
    "    \n",
    "    Returns:\n",
    "    number of days away from the holidy converted to a score [0, 1] exp(-x**2/21**2), \n",
    "    where 21 (3 weeks) is chosen as sigma of the gaussian.\n",
    "    \"\"\"\n",
    "    hdaynamed = dfhday[ dfhday[\"name\"] == hname ]\n",
    "    if hdaynamed is None or len(hdaynamed)==0:\n",
    "        print(\"ERROR: holiday: %s, is not found. Return NaN.\"%hname)\n",
    "        return np.nan\n",
    "    ndays = (test_date - hdaynamed[\"date\"]).dt.days.abs().min()\n",
    "    ndexp = np.exp(-ndays**2/(21**2)) # sigma is 21\n",
    "    \n",
    "    #return ndays\n",
    "    return ndexp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_count(data_clean = None, by = \"Posted_year\", column = \"Posted_month\", title = \"Year\"):\n",
    "    \"\"\"\n",
    "    Plot the counting for column separated by --by-- variable\n",
    "    \"\"\"\n",
    "    for var in range(data_clean[by].min(), data_clean[by].max()+1):\n",
    "        data_slice = data_clean[data_clean[by] == var].copy()\n",
    "        plt.figure()\n",
    "        ax = sns.countplot(x= column, data= data_slice)\n",
    "        ax.set_title(title+\" = %d\"%var)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "for year in range(Carters_clean[\"Posted_year\"].min(), Carters_clean[\"Posted_year\"].max()+1):\n",
    "    data_year = Carters_clean[Carters_clean[\"Posted_year\"] == year].copy()\n",
    "    plt.figure()\n",
    "    ax = sns.countplot(x=\"Posted_weekday\", data= data_year)\n",
    "    ax.set_title(\"Year = %d\"%year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta, date\n",
    "def features(data):\n",
    "    \"\"\"\n",
    "    calculate features as X as well as prediction for having any discount or not in the next, say 3, days!\n",
    "    \"\"\"\n",
    "    feature_dict = {\n",
    "        \"Date\":[],\n",
    "        \"ndays_of_deal\":[], # maximum of how many days does the current day's deal lasted\n",
    "        \"avg_comments\":[], # average comments\n",
    "        \"avg_bookmarks\":[], # average bookmarks\n",
    "        \"avg_shares\":[], # average shares\n",
    "        \"year\": [], \"month\": [], \"day\":[], \"weekday\": [],\n",
    "        \"discount_today\":[], # 0: no discount today, 1: with discount today\n",
    "        \"avg_discount\":[], # average discount of today's deals\n",
    "        \"Y_discount_1d\":[], # discount or not in the next 1 day\n",
    "        \"Y_avg_discount_1d\":[], # average amount of discount in the next 1 day\n",
    "        \"Y_discount_3d\":[], # discount or not in the next 3 days\n",
    "        \"Y_avg_discount_3d\":[], # average amount of discount in the next 3 days\n",
    "        \"Y_discount_7d\":[], # discount or not in the next 7 days\n",
    "        \"Y_avg_discount_7d\":[], # average amount of discount in the next 7 days\n",
    "        \"Y_discount_14d\":[], # discount or not in the next 14 days\n",
    "        \"Y_avg_discount_14d\":[], # average amount of discount in the next 14 days\n",
    "    }\n",
    "    # lagging variables\n",
    "    # for example: discount_past1day meaning:\n",
    "    #   in the past 1 day (yesterday) whether or not there is discount, 0 or 1\n",
    "    #   do it for the past 1 -- 7 days\n",
    "    feature_dict.update({\"discount_past%dday\"%i:[] for i in range(1,8)})\n",
    "    # another example: discount_min_past15day meaning:\n",
    "    #   in the past 15 days the mininum discount of one of the days\n",
    "    #   do it for maximum/mean as well as for 30 days\n",
    "    feature_dict.update({\"discount_%s_past%dday\"%(s,i):[] for s in ['min', 'max', 'mean'] for i in [15, 30]})\n",
    "    \n",
    "    start_date = data[\"Posted_date\"].min()\n",
    "    ndays = int((data[\"Posted_date\"].max() - start_date).days) + 1 - 3\n",
    "    for jd in range(ndays):\n",
    "        today = start_date + timedelta(jd)\n",
    "        data_today = data[data[\"Posted_date\"]==today]\n",
    "        feature_dict[\"year\"].append(today.year)\n",
    "        feature_dict[\"month\"].append(today.month)\n",
    "        feature_dict[\"day\"].append(today.day)\n",
    "        feature_dict[\"weekday\"].append(today.weekday())\n",
    "        for ndp in [1, 3,7,14]:\n",
    "            data_nextnd = data[(data[\"Posted_date\"]>today) & (data[\"Posted_date\"]<=today+timedelta(ndp))]\n",
    "            \n",
    "            if data_nextnd is None or len(data_nextnd)==0:\n",
    "                feature_dict[\"Y_discount_%dd\"%ndp].append(0)\n",
    "                feature_dict[\"Y_avg_discount_%dd\"%ndp].append(0)\n",
    "            else:\n",
    "                feature_dict[\"Y_discount_%dd\"%ndp].append(1)\n",
    "                # calculate the average discount in the future n-days\n",
    "                # use ranges [0, 4]% -> 0; [5, 14]% -> 10%, [15, 24]% -> 20%\n",
    "                avg_f = data_nextnd[\"discount_per_cent\"].mean()\n",
    "                avg_d = 0\n",
    "                for i in range(11):\n",
    "                    if (avg_f >= i*10 - 5) and (avg_f < i*10 + 5):\n",
    "                        avg_d = i*10\n",
    "                        break\n",
    "                feature_dict[\"Y_avg_discount_%dd\"%ndp].append(avg_d)\n",
    "            \n",
    "        ndays_deal, avg_disc, avg_comm, avg_book, avg_shar = 0, 0., 0., 0., 0.\n",
    "        if (data_today is not None) and (len(data_today)>0):\n",
    "            ndays_deal = 1 + int((data_today[\"End_date\"].max() - data_today[\"Posted_date\"].iloc[0]).days) \n",
    "            avg_disc = data_today[\"discount_per_cent\"].mean() \n",
    "            avg_comm = data_today[\"Comments_count\"].mean() \n",
    "            avg_book = data_today[\"Bookmarks_count\"].mean() \n",
    "            avg_shar = data_today[\"Shares_count\"].mean()\n",
    "            \n",
    "        # lagging variables\n",
    "        for nd_past in range(1, 8):\n",
    "            # only when jd >= nd_past, one can calculate the lagging variable using the past\n",
    "            # nd_past days\n",
    "            if jd < nd_past:\n",
    "                feature_dict[\"discount_past%dday\"%nd_past].append(np.nan) # or use nan or 0???\n",
    "            else:\n",
    "                #feature_dict[\"discount_past%dday\"%nd_past].append( feature_dict[\"Y_discount_1d\"][jd - nd_past])\n",
    "                feature_dict[\"discount_past%dday\"%nd_past].append( feature_dict[\"discount_today\"][-nd_past])\n",
    "        for nd_past in [15, 30]:\n",
    "            if jd < nd_past:\n",
    "                for s in ['min', 'max', 'mean']:\n",
    "                    feature_dict[\"discount_%s_past%dday\"%(s,nd_past)].append(np.nan) # or use 0???\n",
    "            else:\n",
    "                #nd_past_discounts = np.array( feature_dict[\"Y_avg_discount_1d\"][jd-nd_past:jd] )\n",
    "                nd_past_discounts = np.array( feature_dict[\"avg_discount\"][jd-nd_past:jd] )\n",
    "                feature_dict[\"discount_min_past%dday\"%nd_past].append(nd_past_discounts.min())\n",
    "                feature_dict[\"discount_max_past%dday\"%nd_past].append(nd_past_discounts.max())\n",
    "                feature_dict[\"discount_mean_past%dday\"%nd_past].append(nd_past_discounts.mean())\n",
    "            \n",
    " \n",
    "        feature_dict[\"Date\"].append(today)\n",
    "        feature_dict[\"ndays_of_deal\"].append(ndays_deal)\n",
    "        feature_dict[\"discount_today\"].append(0 if avg_disc < 1.e-5 else 1)\n",
    "        feature_dict[\"avg_discount\"].append(avg_disc)\n",
    "        feature_dict[\"avg_comments\"].append(avg_comm) \n",
    "        feature_dict[\"avg_bookmarks\"].append(avg_book) \n",
    "        feature_dict[\"avg_shares\"].append(avg_shar) \n",
    "    \n",
    "    pd_feature = pd.DataFrame(feature_dict)\n",
    "    pd_feature[\"Date\"] = pd.to_datetime(pd_feature[\"Date\"])\n",
    "\n",
    "    return pd_feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the datasets and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filefolder = \"Datasets\"\n",
    "input_brand_list = [\"Carters\", \"Oshkosh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Brand Posted_date   End_date  Comments_count  Bookmarks_count  \\\n",
      "0  Carters  2020-01-21 2020-01-21             4.0              2.0   \n",
      "1  Carters  2020-01-21 2020-01-21             0.0              4.0   \n",
      "2  Carters  2020-01-21 2020-01-21            10.0             55.0   \n",
      "3  Carters  2020-01-21 2020-01-21            15.0            139.0   \n",
      "6  Carters  2020-01-21 2020-01-21             1.0             14.0   \n",
      "\n",
      "   Shares_count  Posted_year  Posted_month  Posted_day  Posted_weekday  \\\n",
      "0           2.0         2020             1          21               1   \n",
      "1           3.0         2020             1          21               1   \n",
      "2          30.0         2020             1          21               1   \n",
      "3          99.0         2020             1          21               1   \n",
      "6           9.0         2020             1          21               1   \n",
      "\n",
      "   End_year  End_month  End_day  End_weekday  discount_per_cent  \n",
      "0      2020          1       21            1               60.0  \n",
      "1      2020          1       21            1               70.0  \n",
      "2      2020          1       21            1               50.0  \n",
      "3      2020          1       21            1               70.0  \n",
      "6      2020          1       21            1               70.0  \n",
      "     Brand Posted_date   End_date  Comments_count  Bookmarks_count  \\\n",
      "0  Oshkosh  2020-01-21 2020-01-21             0.0              0.0   \n",
      "2  Oshkosh  2020-01-21 2020-01-21             0.0              0.0   \n",
      "3  Oshkosh  2020-01-21 2020-01-21             0.0              6.0   \n",
      "4  Oshkosh  2020-01-21 2020-01-21             1.0             14.0   \n",
      "5  Oshkosh  2020-01-21 2020-01-21             4.0              1.0   \n",
      "\n",
      "   Shares_count  Posted_year  Posted_month  Posted_day  Posted_weekday  \\\n",
      "0           0.0         2020             1          21               1   \n",
      "2           1.0         2020             1          21               1   \n",
      "3          13.0         2020             1          21               1   \n",
      "4          17.0         2020             1          21               1   \n",
      "5           2.0         2020             1          21               1   \n",
      "\n",
      "   End_year  End_month  End_day  End_weekday  discount_per_cent  \n",
      "0      2020          1       21            1               50.0  \n",
      "2      2020          1       21            1               75.0  \n",
      "3      2020          1       21            1               85.0  \n",
      "4      2020          1       21            1               50.0  \n",
      "5      2020          1       21            1               60.0  \n"
     ]
    }
   ],
   "source": [
    "data_clean_dict = dict()\n",
    "year_min, year_max = 9999, 0\n",
    "for brand in input_brand_list:\n",
    "    filename = input_filefolder+\"/\"+brand+\".csv\"\n",
    "    data_raw = pd.read_csv(filename)\n",
    "    #print(data_raw.head(2))\n",
    "    #print(data_raw.columns)\n",
    "    data_clean = clean(data_raw)\n",
    "    print(data_clean.head())\n",
    "    data_clean_dict[brand] = data_clean\n",
    "    \n",
    "    # calculate the year range for holiday variables later\n",
    "    ymin,ymax=data_clean[\"Posted_year\"].min()-1, data_clean[\"Posted_year\"].max()+2\n",
    "    year_min = ymin if ymin < year_min else year_min\n",
    "    year_max = ymax if ymax > year_max else year_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Prepare the holiday list dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holiday year range: range(2010, 2022)\n",
      "        date                       name\n",
      "0 2016-01-01              New_Years_Day\n",
      "1 2016-01-18  Martin_Luther_King_Jr_Day\n",
      "2 2016-02-15       Washingtons_Birthday\n",
      "3 2016-05-30               Memorial_Day\n",
      "4 2016-07-04           Independence_Day\n",
      "{'Washingtons_Birthday', 'Veterans_Day', 'Memorial_Day', 'Labor_Day', 'Martin_Luther_King_Jr_Day', 'Thanksgiving', 'Independence_Day', 'Christmas_Day', 'New_Years_Day', 'Columbus_Day'}\n"
     ]
    }
   ],
   "source": [
    "# consider holidays from year before and year after, because the closest holiday may not in the\n",
    "# same year as the date under consideration\n",
    "hyearrange=range(year_min, year_max)\n",
    "print(\"holiday year range:\", hyearrange)\n",
    "pd_holiday = get_holidays(hyearrange)\n",
    "print(pd_holiday.head())\n",
    "holidayset = set([h for h in pd_holiday[\"name\"]])\n",
    "print(holidayset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand:Carters\n",
      "holiday: Washingtons_Birthday\n",
      "holiday: Veterans_Day\n",
      "holiday: Memorial_Day\n",
      "holiday: Labor_Day\n",
      "holiday: Martin_Luther_King_Jr_Day\n",
      "holiday: Thanksgiving\n",
      "holiday: Independence_Day\n",
      "holiday: Christmas_Day\n",
      "holiday: New_Years_Day\n",
      "holiday: Columbus_Day\n",
      "Saved:Datasets/Carters_features.csv\n",
      "\n",
      "Brand:Oshkosh\n",
      "holiday: Washingtons_Birthday\n",
      "holiday: Veterans_Day\n",
      "holiday: Memorial_Day\n",
      "holiday: Labor_Day\n",
      "holiday: Martin_Luther_King_Jr_Day\n",
      "holiday: Thanksgiving\n",
      "holiday: Independence_Day\n",
      "holiday: Christmas_Day\n",
      "holiday: New_Years_Day\n",
      "holiday: Columbus_Day\n",
      "Saved:Datasets/Oshkosh_features.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for brand in input_brand_list:\n",
    "    data_clean = data_clean_dict[brand]\n",
    "    print(\"Brand:%s\"%brand)\n",
    "    data_feature = features(data_clean)\n",
    "    data_feature_holiday = data_feature[[\"Date\"]].copy()\n",
    "    for h in holidayset:\n",
    "        print(\"holiday: %s\"%h)\n",
    "        data_feature_holiday[\"nday_away_\"+h] = \\\n",
    "        data_feature_holiday.apply(lambda row: ndays_from_holiday(pd_holiday, h, row[\"Date\"]), axis=1)  \n",
    "    #print(data_feature_holiday.head())\n",
    "    data_feature_holiday[\"nday_away_anyholiday\"] = \\\n",
    "    data_feature_holiday[[\"nday_away_\"+h for h in holidayset]].max(axis=1)\n",
    "    data_feature_update = pd.concat([data_feature, data_feature_holiday.drop([\"Date\"], axis=1)], axis=1)\n",
    "    data_feature_update.drop([\"ndays_of_deal\"], axis=1, inplace=True)\n",
    "    data_feature.dropna(inplace=True)\n",
    "    fileoutname = input_filefolder+\"/\"+brand+\"_features.csv\"\n",
    "    data_feature_update.to_csv(fileoutname)\n",
    "    print(\"Saved:%s\\n\"%fileoutname)\n",
    "    #print(data_feature_update.head())\n",
    "    #print(len(data_feature_update.columns), data_feature_update.columns)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
